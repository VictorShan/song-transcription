
@misc{wav2vecTransfer,
      title={Transfer Learning of wav2vec 2.0 for Automatic Lyric Transcription},
      author={Longshen Ou and Xiangming Gu and Ye Wang},
      year={2022},
      eprint={2207.09747},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@misc{wav2vec,
      title={wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations},
      author={Alexei Baevski and Henry Zhou and Abdelrahman Mohamed and Michael Auli},
      year={2020},
      eprint={2006.11477},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{Librispeech,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title={Librispeech: An ASR corpus based on public domain audio books},
  year={2015},
  volume={},
  number={},
  pages={5206-5210},
  doi={10.1109/ICASSP.2015.7178964}
}

@misc{whisper,
      title={Robust Speech Recognition via Large-Scale Weak Supervision},
      author={Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey and Ilya Sutskever},
      year={2022},
      eprint={2212.04356},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@INPROCEEDINGS{LyricAlignAcoustic,
  author={Sharma, Bidisha and Gupta, Chitralekha and Li, Haizhou and Wang, Ye},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title={Automatic Lyrics-to-audio Alignment on Polyphonic Music Using Singing-adapted Acoustic Models},
  year={2019},
  volume={},
  number={},
  pages={396-400},
  doi={10.1109/ICASSP.2019.8682582}
}

@article{Audio2Score,
    url = {http://dx.doi.org/10.1017/ATSIP.2021.4},
    year = {2021},
    volume = {10},
    journal = {APSIPA Transactions on Signal and Information Processing},
    title = {Audio-to-score singing transcription based on a CRNN-HSMM hybrid model},
    doi = {10.1017/ATSIP.2021.4},
    issn = {2048-7703},
    number = {1},
    pages = {-},
    author = {Ryo Nishikimi and Eita Nakamura and Masataka Goto and Kazuyoshi Yoshii}
}

@INPROCEEDINGS{PhonemeInformed,
  author={Yong, Sangeon and Su, Li and Nam, Juhan},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title={A Phoneme-Informed Neural Network Model For Note-Level Singing Transcription},
  year={2023},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICASSP49357.2023.10096707}
}

@inproceedings{Hansen,
  title={Recognition Of Phonemes In A-Cappella Recordings Using Temporal Patterns And Mel Frequency Cepstral Coefficients},
  author={Jens Kofod Hansen},
  year={2012},
  url={https://api.semanticscholar.org/CorpusID:37419482}
}

@inproceedings{KaraokeApp,
  title={Singing voice detection for karaoke application},
  author={Arun Shenoy and Yuansheng Wu and Ye Wang},
  booktitle={Visual Communications and Image Processing},
  year={2005},
  url={https://api.semanticscholar.org/CorpusID:2889745}
}

@ARTICLE{BayesianAST,
  author={Nishikimi, Ryo and Nakamura, Eita and Goto, Masataka and Itoyama, Katsutoshi and Yoshii, Kazuyoshi},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title={Bayesian Singing Transcription Based on a Hierarchical Generative Model of Keys, Musical Notes, and F0 Trajectories},
  year={2020},
  volume={28},
  number={},
  pages={1678-1691},
  doi={10.1109/TASLP.2020.2996095}
}

@article{whisperX,
  title={WhisperX: Time-Accurate Speech Transcription of Long-Form Audio},
  author={Bain, Max and Huh, Jaesung and Han, Tengda and Zisserman, Andrew},
  journal={INTERSPEECH 2023},
  year={2023}
}

@inproceedings{CSD,
  title={Children's Song Dataset for Singing Voice Research},
  author={Soonbeom Choi and Wonil Kim and Saebyul Park and Sangeon Yong and Juhan Nam},
  booktitle={KAIST},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:244992211}
}

@inproceedings{DALI,
    Author = {Meseguer-Brocal, Gabriel and Cohen-Hadria, Alice and Peeters, Geoffroy},
    Booktitle = {19th International Society for Music Information Retrieval Conference},
    Editor = {ISMIR},
    Month = {September},
    Title = {DALI: a large Dataset of synchronized Audio, LyrIcs and notes, automatically created using teacher-student machine learning paradigm.},
    Year = {2018}
}

@INPROCEEDINGS{NUSDataset,
  author={Duan, Zhiyan and Fang, Haotian and Li, Bo and Sim, Khe Chai and Wang, Ye},
  booktitle={2013 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference},
  title={The NUS sung and spoken lyrics corpus: A quantitative comparison of singing and speech},
  year={2013},
  volume={},
  number={},
  pages={1-9},
  doi={10.1109/APSIPA.2013.6694316}
}

@misc{JamendoLyrics,
      title={End-to-end Lyrics Alignment for Polyphonic Music Using an Audio-to-Character Recognition Model},
      author={Daniel Stoller and Simon Durand and Sebastian Ewert},
      year={2019},
      eprint={1902.06797},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}

@misc{musDB18,
      title={The 2018 Signal Separation Evaluation Campaign},
      author={Fabian-Robert St√∂ter and Antoine Liutkus and Nobutaka Ito},
      year={2018},
      eprint={1804.06267},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@inproceedings{Demux,
  title={Hybrid Transformers for Music Source Separation},
  author={Rouard, Simon and Massa, Francisco and D{\'e}fossez, Alexandre},
  booktitle={ICASSP 23},
  year={2023}
}

@misc{CMUDict,
  author = {CMU},
  year = {2023},
  title = {CMU Pronouncing Dictionary},
  url = {http://www.speech.cs.cmu.edu/cgi-bin/cmudict}
}


@inproceedings{SpecAugment,
   title={SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition},
   url={http://dx.doi.org/10.21437/Interspeech.2019-2680},
   DOI={10.21437/interspeech.2019-2680},
   booktitle={Interspeech 2019},
   publisher={ISCA},
   author={Park, Daniel S. and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D. and Le, Quoc V.},
   year={2019},
   collection={interspeech_2019}
}

@INPROCEEDINGS{PhonationMode,
  author={Wang, Yixin and Wei, Wei and Wang, Ye},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title={Phonation Mode Detection in Singing: A Singer Adapted Model},
  year={2023},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICASSP49357.2023.10095669}
}

@online{MFCC,
  author = {Raissi, Maziar},
  title = {Mel-Spectrogram and MFCCs},
  year = {2021},
  url = {https://www.youtube.com/watch?v=hF72sY70_IQ}
}

@article{CTC,
  author = {Hannun, Awni},
  title = {Sequence Modeling with CTC},
  journal = {Distill},
  year = {2017},
  note = {https://distill.pub/2017/ctc},
  doi = {10.23915/distill.00008}
}